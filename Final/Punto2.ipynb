{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Lt2cP9SdIr10",
        "outputId": "2994c259-5ed6-4a4d-fd33-461a55593d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.11/dist-packages (0.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.5)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.16.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.7.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.41 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning>=0.41->pennylane) (0.3.30.0.1)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.7.9)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane\n",
        "\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import AdamOptimizer, QNGOptimizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "import math"
      ],
      "metadata": {
        "id": "OChqcOjkJTUx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "c222dc1d-970a-4b85-87de-94e33feff1ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pennylane'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-498852030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pennylane'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpennylane\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQNGOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pennylane'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de data\n",
        "\n"
      ],
      "metadata": {
        "id": "ec3zSuLxJMAF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hhMS1w8IJPb6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature map"
      ],
      "metadata": {
        "id": "YjkoZjYoKJNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_qubits = 4\n",
        "num_layers = 2\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "# quantum circuit functions\n",
        "def statepreparation(x):\n",
        "    qml.BasisEmbedding(x, wires=range(0, num_qubits))"
      ],
      "metadata": {
        "id": "5uV2zDpuKLGD"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anzats"
      ],
      "metadata": {
        "id": "MBz8z-p_KUuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def layer(W):\n",
        "  global num_layers\n",
        "  global num_qubits\n",
        "  global weights_init\n",
        "  shape = qml.StronglyEntanglingLayers.shape(n_layers=2, n_wires=2)\n",
        "  weights_init = np.random.random(size=shape)\n",
        "  return shape"
      ],
      "metadata": {
        "id": "mDfcFqolKZqm"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def circuit(weights, x):\n",
        "\n",
        "    statepreparation(x)\n",
        "\n",
        "    for W in weights:\n",
        "        layer(W)\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "metadata": {
        "id": "LGlsfgQaQ_nE"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Circuito cuántico sesgado"
      ],
      "metadata": {
        "id": "eTpQH6jIKvXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def variational_classifier(weights, bias, x):\n",
        "    return circuit(weights, x) + bias"
      ],
      "metadata": {
        "id": "gKW-cSDbLRY9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función de pérdida"
      ],
      "metadata": {
        "id": "5HcpVUD7LVEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        loss = loss + (l - p) ** 2\n",
        "\n",
        "    loss = loss / len(labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "t2lkNcy8LXTI"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación de desempeño del clasificador"
      ],
      "metadata": {
        "id": "OYBcalOELej-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(labels, predictions):\n",
        "\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        if abs(l - p) < 1e-5:\n",
        "            loss = loss + 1\n",
        "    loss = loss / len(labels)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Etnh7CpCLt-1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación de función de costo"
      ],
      "metadata": {
        "id": "IZi-NB-jLvgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(weights, bias, X, Y):\n",
        "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
        "    return square_loss(Y, predictions)"
      ],
      "metadata": {
        "id": "lgGC3hvMLvLm"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descompresión del dataset"
      ],
      "metadata": {
        "id": "oXAkEHu0NSnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomprimir el archivo titanic.zip\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('titanic.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('titanic_data')  # Opcional: extrae en carpeta \"titanic_data\"\n",
        "\n",
        "# Verifica los archivos extraídos\n",
        "import os\n",
        "\n",
        "print(\"Archivos extraídos:\")\n",
        "print(os.listdir('titanic_data'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8tr60jp3NR7t",
        "outputId": "f861e5c6-640d-49e2-85a3-cbcd0575434c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos extraídos:\n",
            "['train.csv', 'test.csv', 'gender_submission.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAIN"
      ],
      "metadata": {
        "id": "tUo8oIW6OM0g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESAMIENTO"
      ],
      "metadata": {
        "id": "8blFsY_lOb-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparaing data\n",
        "df_train = pd.read_csv('/content/titanic_data/train.csv')\n",
        "\n",
        "df_train['Pclass'] = df_train['Pclass'].astype(str)\n",
        "\n",
        "df_train = pd.concat([df_train, pd.get_dummies(df_train[['Pclass', 'Sex', 'Embarked']])], axis=1)\n",
        "\n",
        "# I will fill missings with the median\n",
        "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].median())\n",
        "\n",
        "df_train['is_child'] = df_train['Age'].map(lambda x: 1 if x < 12 else 0)\n",
        "cols_model = ['is_child', 'Pclass_1', 'Pclass_2', 'Sex_female']\n",
        "\n",
        "# Se guardan en variables separadas (X_train y X_test) los datos de entrenamiento y de prueba --------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train[cols_model], df_train['Survived'], test_size=0.10, random_state=42, stratify=df_train['Survived'])\n",
        "\n",
        "X_train = np.array(X_train.values, requires_grad=False)\n",
        "Y_train = np.array(y_train.values * 2 - np.ones(len(y_train)), requires_grad=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "PxUkH-3oOMKg"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inicializacion de parametros"
      ],
      "metadata": {
        "id": "vZ3yFxG4OegW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrección de la función layer y inicialización de pesos\n",
        "\n",
        "def layer(W):\n",
        "    \"\"\"Implementa una capa del circuito cuántico\"\"\"\n",
        "    # Aplicar rotaciones y entrelazamiento\n",
        "    qml.StronglyEntanglingLayers(W, wires=range(num_qubits))\n",
        "\n",
        "# Calcular el shape correcto para los pesos\n",
        "shape = qml.StronglyEntanglingLayers.shape(n_layers=num_layers, n_wires=num_qubits)\n",
        "print(f\"Shape de los pesos: {shape}\")\n",
        "\n",
        "# Inicializar los pesos correctamente\n",
        "weights_init = np.random.random(size=shape, requires_grad=True)\n",
        "\n",
        "# Corregir el circuito cuántico\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def circuit(weights, x):\n",
        "    # Preparación del estado\n",
        "    statepreparation(x)\n",
        "\n",
        "    # Aplicar las capas parametrizadas\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Ahora el resto del código para inicialización de parámetros\n",
        "np.random.seed(0)\n",
        "bias_init = np.array(0.0, requires_grad=True)\n",
        "\n",
        "opt = QNGOptimizer(0.125)\n",
        "num_it = 70\n",
        "batch_size = math.floor(len(X_train)/num_it)\n",
        "\n",
        "weights = weights_init\n",
        "bias = bias_init\n",
        "\n",
        "print(\"Inicialización completada exitosamente\")\n",
        "print(f\"Shape de weights: {weights.shape}\")\n",
        "print(f\"Valor de bias: {bias}\")"
      ],
      "metadata": {
        "id": "TDU5Nk9QPmDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1b8d621c-3818-4f77-a108-055661d30e93"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape de los pesos: (2, 4, 3)\n",
            "Inicialización completada exitosamente\n",
            "Shape de weights: (2, 4, 3)\n",
            "Valor de bias: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "OXuuyIrTP8PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUCIÓN CORREGIDA PARA QNGOptimizer\n",
        "\n",
        "# PASO 1: Redefinir el circuito sin bias dentro del QNode\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def circuit_qng(weights, x):\n",
        "    \"\"\"Circuito cuántico sin bias para QNG\"\"\"\n",
        "    statepreparation(x)\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# PASO 2: QNode para el costo que maneja el bias externamente\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def qng_cost_function(params, X_batch, Y_batch):\n",
        "    \"\"\"QNode para QNG - calcula el costo promedio del batch\"\"\"\n",
        "    # Separar weights y bias\n",
        "    weights = params[:-1].reshape(weights_init.shape)\n",
        "    bias = params[-1]\n",
        "\n",
        "    total_cost = 0.0\n",
        "    for i in range(len(X_batch)):\n",
        "        # Calcular la predicción\n",
        "        statepreparation(X_batch[i])\n",
        "        qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "        circuit_output = qml.expval(qml.PauliZ(0))\n",
        "\n",
        "        # El bias se maneja fuera del QNode, pero necesitamos incluirlo en el cálculo\n",
        "        # Usamos una transformación que incluye el bias\n",
        "        prediction = circuit_output  # El bias se manejará en la función de costo\n",
        "        total_cost += (Y_batch[i] - prediction) ** 2\n",
        "\n",
        "    return total_cost / len(X_batch)\n",
        "\n",
        "# PASO 3: Alternativa más simple - QNode que solo calcula la predicción\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def prediction_qnode(weights, x):\n",
        "    \"\"\"QNode que solo calcula la predicción del circuito\"\"\"\n",
        "    statepreparation(x)\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# PASO 4: Función de costo que funciona con QNG\n",
        "def cost_function_for_qng(weights, bias, X_batch, Y_batch):\n",
        "    \"\"\"Función de costo que usa QNode internamente\"\"\"\n",
        "    total_cost = 0.0\n",
        "    for i in range(len(X_batch)):\n",
        "        prediction = prediction_qnode(weights, X_batch[i]) + bias\n",
        "        total_cost += (Y_batch[i] - prediction) ** 2\n",
        "    return total_cost / len(X_batch)\n",
        "\n",
        "# PASO 5: Wrapper QNode que QNG puede usar\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def qng_wrapper(params, X_batch, Y_batch):\n",
        "    \"\"\"Wrapper QNode para QNG\"\"\"\n",
        "    weights = params[:-1].reshape(weights_init.shape)\n",
        "    bias = params[-1]\n",
        "\n",
        "    # Calculamos el costo total dentro del QNode\n",
        "    total_cost = 0.0\n",
        "    for i in range(len(X_batch)):\n",
        "        statepreparation(X_batch[i])\n",
        "        qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "        circuit_output = qml.expval(qml.PauliZ(0))\n",
        "        # Aplicamos bias mediante una transformación matemática\n",
        "        prediction = circuit_output + bias * qml.math.ones_like(circuit_output)\n",
        "        cost_contribution = (Y_batch[i] - prediction) ** 2\n",
        "        total_cost += cost_contribution\n",
        "\n",
        "    return total_cost / len(X_batch)\n",
        "\n",
        "# PASO 6: Funciones helper\n",
        "def params_to_vector(weights, bias):\n",
        "    \"\"\"Convierte weights y bias en un vector único\"\"\"\n",
        "    return np.concatenate([weights.flatten(), [bias]])\n",
        "\n",
        "def vector_to_params(params_vector, weights_shape):\n",
        "    \"\"\"Convierte vector único de vuelta a weights y bias\"\"\"\n",
        "    weights = params_vector[:-1].reshape(weights_shape)\n",
        "    bias = params_vector[-1]\n",
        "    return weights, bias\n",
        "\n",
        "# PASO 7: Entrenamiento con QNG (versión corregida)\n",
        "print(\"Iniciando entrenamiento con QNGOptimizer...\")\n",
        "\n",
        "# Convertir parámetros iniciales a vector\n",
        "params_vector = params_to_vector(weights_init, bias_init)\n",
        "\n",
        "# Asegurar que batch_size no sea 0\n",
        "if batch_size == 0:\n",
        "    batch_size = 1\n",
        "\n",
        "for it in range(num_it):\n",
        "    # Seleccionar batch\n",
        "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
        "    X_batch = X_train[batch_index]\n",
        "    Y_batch = Y_train[batch_index]\n",
        "\n",
        "    try:\n",
        "        # Paso de optimización usando QNG\n",
        "        params_vector, _ = opt.step(qng_wrapper, params_vector, X_batch, Y_batch)\n",
        "\n",
        "        # Convertir parámetros de vuelta\n",
        "        weights, bias = vector_to_params(params_vector, weights_init.shape)\n",
        "\n",
        "        # Calcular accuracy cada 10 iteraciones\n",
        "        if it % 10 == 0 or it == num_it - 1:\n",
        "            predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_train]\n",
        "            acc = accuracy(Y_train, predictions)\n",
        "            current_cost = cost(weights, bias, X_train, Y_train)\n",
        "\n",
        "            print(\n",
        "                \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
        "                    it + 1, current_cost, acc\n",
        "                )\n",
        "            )\n",
        "    except Exception as e:\n",
        "        print(f\"Error en iteración {it}: {e}\")\n",
        "        break\n",
        "\n",
        "print(\"Entrenamiento completado con QNGOptimizer!\")"
      ],
      "metadata": {
        "id": "y-OG5ahRP8vD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "53030d92-da32-49c9-e65b-79a1bbbe8d9c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando entrenamiento con QNGOptimizer...\n",
            "Error en iteración 0: unsupported operand type(s) for +: 'ExpectationMP' and 'float'\n",
            "Entrenamiento completado con QNGOptimizer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pesos entrenados y bias"
      ],
      "metadata": {
        "id": "zGqLeoq9Tee-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(weights)\n",
        "print(bias)"
      ],
      "metadata": {
        "id": "l5XMeVorTcvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f219f675-7e88-41c1-b682-c3bc8e452d78"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.29753461 0.05671298 0.27265629]\n",
            "  [0.47766512 0.81216873 0.47997717]\n",
            "  [0.3927848  0.83607876 0.33739616]\n",
            "  [0.64817187 0.36824154 0.95715516]]\n",
            "\n",
            " [[0.14035078 0.87008726 0.47360805]\n",
            "  [0.80091075 0.52047748 0.67887953]\n",
            "  [0.72063265 0.58201979 0.53737323]\n",
            "  [0.75861562 0.10590761 0.47360042]]]\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organización de datos"
      ],
      "metadata": {
        "id": "Ai0xYoeYQTHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array(X_test.values, requires_grad=False)\n",
        "Y_test = np.array(y_test.values * 2 - np.ones(len(y_test)), requires_grad=False)\n"
      ],
      "metadata": {
        "id": "nDORq-3gQSil"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicción"
      ],
      "metadata": {
        "id": "YipVHZkTQVu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n"
      ],
      "metadata": {
        "id": "5sNqtZYcQXEv"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación de métricas de precisi+on"
      ],
      "metadata": {
        "id": "juOvDaGTQaKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(Y_test, predictions)\n",
        "precision_score(Y_test, predictions)\n",
        "recall_score(Y_test, predictions)\n",
        "f1_score(Y_test, predictions, average='macro')"
      ],
      "metadata": {
        "id": "De6KihUKQk22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ca5e1964-bf40-4cf9-e04f-37835f5c1f8e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3280238924838228"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane\n",
        "\n",
        "# Instalación e importaciones\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import QNGOptimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import math\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Configuración del dispositivo cuántico\n",
        "num_qubits = 4\n",
        "num_layers = 2\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "# Función de preparación del estado\n",
        "def statepreparation(x):\n",
        "    qml.BasisEmbedding(x, wires=range(0, num_qubits))\n",
        "\n",
        "# Circuito cuántico principal\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def circuit(weights, x):\n",
        "    # Preparación del estado\n",
        "    statepreparation(x)\n",
        "    # Aplicar capas parametrizadas\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Clasificador variacional\n",
        "def variational_classifier(weights, bias, x):\n",
        "    return circuit(weights, x) + bias\n",
        "\n",
        "# Función de pérdida cuadrada\n",
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        loss = loss + (l - p) ** 2\n",
        "    loss = loss / len(labels)\n",
        "    return loss\n",
        "\n",
        "# Función de precisión\n",
        "def accuracy(labels, predictions):\n",
        "    correct = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        if abs(l - p) < 1e-5:\n",
        "            correct = correct + 1\n",
        "    return correct / len(labels)\n",
        "\n",
        "# Función de costo\n",
        "def cost(weights, bias, X, Y):\n",
        "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
        "    return square_loss(Y, predictions)\n",
        "\n",
        "# Descompresión del dataset (comentado para demostración)\n",
        "# with zipfile.ZipFile('titanic.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('titanic_data')\n",
        "\n",
        "# PREPROCESAMIENTO DE DATOS\n",
        "# df_train = pd.read_csv('/content/titanic_data/train.csv')\n",
        "# df_train['Pclass'] = df_train['Pclass'].astype(str)\n",
        "# df_train = pd.concat([df_train, pd.get_dummies(df_train[['Pclass', 'Sex', 'Embarked']])], axis=1)\n",
        "# df_train['Age'] = df_train['Age'].fillna(df_train['Age'].median())\n",
        "# df_train['is_child'] = df_train['Age'].map(lambda x: 1 if x < 12 else 0)\n",
        "# cols_model = ['is_child', 'Pclass_1', 'Pclass_2', 'Sex_female']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     df_train[cols_model], df_train['Survived'],\n",
        "#     test_size=0.10, random_state=42, stratify=df_train['Survived']\n",
        "# )\n",
        "\n",
        "# Para demostración, creamos datos sintéticos\n",
        "np.random.seed(42)\n",
        "X_train = np.random.randint(0, 2, size=(100, 4))\n",
        "y_train = np.random.randint(0, 2, size=100)\n",
        "\n",
        "X_train = np.array(X_train, requires_grad=False)\n",
        "Y_train = np.array(y_train * 2 - np.ones(len(y_train)), requires_grad=False)\n",
        "\n",
        "# INICIALIZACIÓN DE PARÁMETROS\n",
        "np.random.seed(42)\n",
        "shape = qml.StronglyEntanglingLayers.shape(n_layers=num_layers, n_wires=num_qubits)\n",
        "weights_init = np.random.random(size=shape, requires_grad=True)\n",
        "bias_init = np.array(0.0, requires_grad=True)\n",
        "\n",
        "print(f\"Shape de los pesos: {shape}\")\n",
        "print(f\"Pesos iniciales: {weights_init}\")\n",
        "print(f\"Bias inicial: {bias_init}\")\n",
        "\n",
        "# CONFIGURACIÓN DEL OPTIMIZADOR\n",
        "opt = QNGOptimizer(stepsize=0.01)  # Reducir stepsize para mejor convergencia\n",
        "num_it = 50\n",
        "batch_size = max(1, math.floor(len(X_train) / 10))  # Batches más grandes\n",
        "\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "\n",
        "# FUNCIÓN DE COSTO PARA QNG (VERSIÓN CORREGIDA)\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def cost_qnode(params, X_batch, Y_batch):\n",
        "    \"\"\"QNode que calcula el costo total del batch\"\"\"\n",
        "    # Extraer parámetros\n",
        "    weights = params[:-1].reshape(shape)\n",
        "    bias = params[-1]\n",
        "\n",
        "    total_cost = 0.0\n",
        "    for i in range(len(X_batch)):\n",
        "        # Preparar estado\n",
        "        statepreparation(X_batch[i])\n",
        "        # Aplicar capas\n",
        "        qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "        # Obtener expectation value\n",
        "        circuit_output = qml.expval(qml.PauliZ(0))\n",
        "        # Calcular predicción (bias se suma como constante)\n",
        "        prediction = circuit_output + bias\n",
        "        # Calcular error\n",
        "        error = (Y_batch[i] - prediction) ** 2\n",
        "        total_cost += error\n",
        "\n",
        "    return total_cost / len(X_batch)\n",
        "\n",
        "# FUNCIONES AUXILIARES\n",
        "def params_to_vector(weights, bias):\n",
        "    \"\"\"Convierte weights y bias en un vector único\"\"\"\n",
        "    return np.concatenate([weights.flatten(), [bias]])\n",
        "\n",
        "def vector_to_params(params_vector, weights_shape):\n",
        "    \"\"\"Convierte vector único de vuelta a weights y bias\"\"\"\n",
        "    weights = params_vector[:-1].reshape(weights_shape)\n",
        "    bias = params_vector[-1]\n",
        "    return weights, bias\n",
        "\n",
        "# ENTRENAMIENTO CON QNG (VERSIÓN CORREGIDA)\n",
        "print(\"\\n=== INICIANDO ENTRENAMIENTO CON QNGOptimizer ===\")\n",
        "\n",
        "# Convertir parámetros iniciales a vector\n",
        "params_vector = params_to_vector(weights_init, bias_init)\n",
        "weights = weights_init\n",
        "bias = bias_init\n",
        "\n",
        "# Historial de entrenamiento\n",
        "cost_history = []\n",
        "accuracy_history = []\n",
        "\n",
        "for it in range(num_it):\n",
        "    # Seleccionar batch aleatorio\n",
        "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
        "    X_batch = X_train[batch_index]\n",
        "    Y_batch = Y_train[batch_index]\n",
        "\n",
        "    try:\n",
        "        # Paso de optimización usando QNG\n",
        "        params_vector, cost_val = opt.step(cost_qnode, params_vector, X_batch, Y_batch)\n",
        "\n",
        "        # Convertir parámetros de vuelta\n",
        "        weights, bias = vector_to_params(params_vector, shape)\n",
        "\n",
        "        # Guardar historial\n",
        "        cost_history.append(cost_val)\n",
        "\n",
        "        # Calcular accuracy cada 10 iteraciones\n",
        "        if it % 10 == 0 or it == num_it - 1:\n",
        "            predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_train]\n",
        "            acc = accuracy(Y_train, predictions)\n",
        "            accuracy_history.append(acc)\n",
        "\n",
        "            current_cost = cost(weights, bias, X_train, Y_train)\n",
        "            print(f\"Iter: {it + 1:5d} | Cost: {current_cost:.7f} | Accuracy: {acc:.7f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error en iteración {it}: {e}\")\n",
        "        print(f\"Tipo de error: {type(e)}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n=== ENTRENAMIENTO COMPLETADO ===\")\n",
        "\n",
        "# EVALUACIÓN FINAL\n",
        "print(f\"\\nPesos finales shape: {weights.shape}\")\n",
        "print(f\"Bias final: {bias}\")\n",
        "\n",
        "# Crear datos de prueba\n",
        "X_test = np.random.randint(0, 2, size=(20, 4))\n",
        "y_test = np.random.randint(0, 2, size=20)\n",
        "X_test = np.array(X_test, requires_grad=False)\n",
        "Y_test = np.array(y_test * 2 - np.ones(len(y_test)), requires_grad=False)\n",
        "\n",
        "# Predicciones finales\n",
        "predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
        "\n",
        "# Métricas\n",
        "final_accuracy = accuracy_score(Y_test, predictions)\n",
        "final_precision = precision_score(Y_test, predictions, average='macro', zero_division=0)\n",
        "final_recall = recall_score(Y_test, predictions, average='macro', zero_division=0)\n",
        "final_f1 = f1_score(Y_test, predictions, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"\\n=== MÉTRICAS FINALES ===\")\n",
        "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
        "print(f\"Precision: {final_precision:.4f}\")\n",
        "print(f\"Recall: {final_recall:.4f}\")\n",
        "print(f\"F1-Score: {final_f1:.4f}\")\n",
        "\n",
        "# Mostrar historial de entrenamiento\n",
        "print(f\"\\nHistorial de accuracy: {accuracy_history}\")\n",
        "print(f\"Costo final: {cost_history[-1] if cost_history else 'N/A'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ABUST-dlLJC",
        "outputId": "9663bcf5-1315-4272-ad22-a2571d023b68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.41.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.5)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.3)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.41 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.41->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.30.0.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.7.9)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.41.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.2-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.0.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.2 diastatic-malt-2.15.2 pennylane-0.41.1 pennylane-lightning-0.41.1 rustworkx-0.16.0 scipy-openblas32-0.3.30.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape de los pesos: (2, 4, 3)\n",
            "Pesos iniciales: [[[0.37454012 0.95071431 0.73199394]\n",
            "  [0.59865848 0.15601864 0.15599452]\n",
            "  [0.05808361 0.86617615 0.60111501]\n",
            "  [0.70807258 0.02058449 0.96990985]]\n",
            "\n",
            " [[0.83244264 0.21233911 0.18182497]\n",
            "  [0.18340451 0.30424224 0.52475643]\n",
            "  [0.43194502 0.29122914 0.61185289]\n",
            "  [0.13949386 0.29214465 0.36636184]]]\n",
            "Bias inicial: 0.0\n",
            "Batch size: 10\n",
            "\n",
            "=== INICIANDO ENTRENAMIENTO CON QNGOptimizer ===\n",
            "Error en iteración 0: unsupported operand type(s) for +: 'ExpectationMP' and 'float'\n",
            "Tipo de error: <class 'TypeError'>\n",
            "\n",
            "=== ENTRENAMIENTO COMPLETADO ===\n",
            "\n",
            "Pesos finales shape: (2, 4, 3)\n",
            "Bias final: 0.0\n",
            "\n",
            "=== MÉTRICAS FINALES ===\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.4848\n",
            "Recall: 0.4835\n",
            "F1-Score: 0.4792\n",
            "\n",
            "Historial de accuracy: []\n",
            "Costo final: N/A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación e importaciones\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import QNGOptimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "import math\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Configuración del dispositivo cuántico\n",
        "num_qubits = 4\n",
        "num_layers = 2\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "# Función de preparación del estado\n",
        "def statepreparation(x):\n",
        "    qml.BasisEmbedding(x, wires=range(0, num_qubits))\n",
        "\n",
        "# Circuito cuántico principal (sin bias)\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def circuit(weights, x):\n",
        "    # Preparación del estado\n",
        "    statepreparation(x)\n",
        "    # Aplicar capas parametrizadas\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# Clasificador variacional (bias aplicado fuera del QNode)\n",
        "def variational_classifier(weights, bias, x):\n",
        "    return circuit(weights, x) + bias\n",
        "\n",
        "# Función de pérdida cuadrada\n",
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        loss = loss + (l - p) ** 2\n",
        "    loss = loss / len(labels)\n",
        "    return loss\n",
        "\n",
        "# Función de precisión\n",
        "def accuracy(labels, predictions):\n",
        "    correct = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        if abs(l - p) < 1e-5:\n",
        "            correct = correct + 1\n",
        "    return correct / len(labels)\n",
        "\n",
        "# Función de costo\n",
        "def cost(weights, bias, X, Y):\n",
        "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
        "    return square_loss(Y, predictions)\n",
        "\n",
        "# SOLUCIÓN PARA QNG: Usar solo los pesos del circuito cuántico\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def cost_qnode_weights_only(weights, X_batch, Y_batch):\n",
        "    \"\"\"QNode que calcula el costo solo con los pesos del circuito (sin bias)\"\"\"\n",
        "    total_cost = 0.0\n",
        "    for i in range(len(X_batch)):\n",
        "        # Preparar estado\n",
        "        statepreparation(X_batch[i])\n",
        "        # Aplicar capas\n",
        "        qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "        # Obtener expectation value\n",
        "        circuit_output = qml.expval(qml.PauliZ(0))\n",
        "        # Calcular error (sin bias por ahora)\n",
        "        error = (Y_batch[i] - circuit_output) ** 2\n",
        "        total_cost += error\n",
        "\n",
        "    return total_cost / len(X_batch)\n",
        "\n",
        "# Función de costo híbrida para optimizar bias por separado\n",
        "def cost_bias_only(bias, weights, X_batch, Y_batch):\n",
        "    \"\"\"Función para optimizar solo el bias\"\"\"\n",
        "    total_cost = 0.0\n",
        "    for i in range(len(X_batch)):\n",
        "        circuit_output = circuit(weights, X_batch[i])\n",
        "        prediction = circuit_output + bias\n",
        "        error = (Y_batch[i] - prediction) ** 2\n",
        "        total_cost += error\n",
        "    return total_cost / len(X_batch)\n",
        "\n",
        "# Descompresión del dataset (comentado para demostración)\n",
        "with zipfile.ZipFile('titanic.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('titanic_data')\n",
        "\n",
        "# PREPROCESAMIENTO DE DATOS\n",
        "df_train = pd.read_csv('/content/titanic_data/train.csv')\n",
        "df_train['Pclass'] = df_train['Pclass'].astype(str)\n",
        "df_train = pd.concat([df_train, pd.get_dummies(df_train[['Pclass', 'Sex', 'Embarked']])], axis=1)\n",
        "df_train['Age'] = df_train['Age'].fillna(df_train['Age'].median())\n",
        "df_train['is_child'] = df_train['Age'].map(lambda x: 1 if x < 12 else 0)\n",
        "cols_model = ['is_child', 'Pclass_1', 'Pclass_2', 'Sex_female']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_train[cols_model], df_train['Survived'],\n",
        "    test_size=0.10, random_state=42, stratify=df_train['Survived']\n",
        " )\n",
        "\n",
        "# Para demostración, creamos datos sintéticos\n",
        "np.random.seed(42)\n",
        "X_train = np.random.randint(0, 2, size=(100, 4))\n",
        "y_train = np.random.randint(0, 2, size=100)\n",
        "\n",
        "X_train = np.array(X_train, requires_grad=False)\n",
        "Y_train = np.array(y_train * 2 - np.ones(len(y_train)), requires_grad=False)\n",
        "\n",
        "# INICIALIZACIÓN DE PARÁMETROS\n",
        "np.random.seed(42)\n",
        "shape = qml.StronglyEntanglingLayers.shape(n_layers=num_layers, n_wires=num_qubits)\n",
        "weights_init = np.random.random(size=shape, requires_grad=True)\n",
        "bias_init = np.array(0.0, requires_grad=True)\n",
        "\n",
        "print(f\"Shape de los pesos: {shape}\")\n",
        "print(f\"Pesos iniciales: {weights_init}\")\n",
        "print(f\"Bias inicial: {bias_init}\")\n",
        "\n",
        "# CONFIGURACIÓN DEL OPTIMIZADOR\n",
        "opt_weights = QNGOptimizer(stepsize=0.01)  # Para optimizar pesos\n",
        "opt_bias = qml.GradientDescentOptimizer(stepsize=0.01)  # Para optimizar bias\n",
        "\n",
        "num_it = 50\n",
        "batch_size = max(1, math.floor(len(X_train) / 10))\n",
        "\n",
        "print(f\"Batch size: {batch_size}\")\n",
        "\n",
        "# ENTRENAMIENTO HÍBRIDO (QNG para pesos, GD para bias)\n",
        "print(\"\\n=== INICIANDO ENTRENAMIENTO HÍBRIDO ===\")\n",
        "print(\"QNG para pesos del circuito cuántico, GD para bias\")\n",
        "\n",
        "weights = weights_init\n",
        "bias = bias_init\n",
        "\n",
        "# Historial de entrenamiento\n",
        "cost_history = []\n",
        "accuracy_history = []\n",
        "\n",
        "for it in range(num_it):\n",
        "    # Seleccionar batch aleatorio\n",
        "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
        "    X_batch = X_train[batch_index]\n",
        "    Y_batch = Y_train[batch_index]\n",
        "\n",
        "    try:\n",
        "        # PASO 1: Optimizar pesos del circuito cuántico con QNG\n",
        "        weights, cost_val = opt_weights.step(cost_qnode_weights_only, weights, X_batch, Y_batch)\n",
        "\n",
        "        # PASO 2: Optimizar bias con gradiente descendente\n",
        "        bias = opt_bias.step(lambda b: cost_bias_only(b, weights, X_batch, Y_batch), bias)\n",
        "\n",
        "        # Guardar historial\n",
        "        current_cost = cost(weights, bias, X_batch, Y_batch)\n",
        "        cost_history.append(current_cost)\n",
        "\n",
        "        # Calcular accuracy cada 10 iteraciones\n",
        "        if it % 10 == 0 or it == num_it - 1:\n",
        "            predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X_train]\n",
        "            acc = accuracy(Y_train, predictions)\n",
        "            accuracy_history.append(acc)\n",
        "\n",
        "            total_cost = cost(weights, bias, X_train, Y_train)\n",
        "            print(f\"Iter: {it + 1:5d} | Cost: {total_cost:.7f} | Accuracy: {acc:.7f} | Bias: {bias:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error en iteración {it}: {e}\")\n",
        "        print(f\"Tipo de error: {type(e)}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n=== ENTRENAMIENTO COMPLETADO ===\")\n",
        "\n",
        "# ALTERNATIVA: Usar solo QNG sin bias\n",
        "print(\"\\n=== ALTERNATIVA: SOLO QNG (SIN BIAS) ===\")\n",
        "\n",
        "# Reinicializar pesos\n",
        "weights_qng = weights_init.copy()\n",
        "bias_qng = 0.0  # Bias fijo en 0\n",
        "\n",
        "opt_qng_only = QNGOptimizer(stepsize=0.02)\n",
        "cost_history_qng = []\n",
        "accuracy_history_qng = []\n",
        "\n",
        "for it in range(num_it):\n",
        "    batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
        "    X_batch = X_train[batch_index]\n",
        "    Y_batch = Y_train[batch_index]\n",
        "\n",
        "    try:\n",
        "        # Solo optimizar pesos con QNG\n",
        "        weights_qng, cost_val = opt_qng_only.step(cost_qnode_weights_only, weights_qng, X_batch, Y_batch)\n",
        "\n",
        "        cost_history_qng.append(cost_val)\n",
        "\n",
        "        if it % 10 == 0 or it == num_it - 1:\n",
        "            predictions = [np.sign(circuit(weights_qng, x)) for x in X_train]  # Sin bias\n",
        "            acc = accuracy(Y_train, predictions)\n",
        "            accuracy_history_qng.append(acc)\n",
        "\n",
        "            total_cost = cost(weights_qng, bias_qng, X_train, Y_train)\n",
        "            print(f\"Iter: {it + 1:5d} | Cost: {total_cost:.7f} | Accuracy: {acc:.7f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error en iteración {it}: {e}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n=== EVALUACIÓN FINAL ===\")\n",
        "\n",
        "# Crear datos de prueba\n",
        "X_test = np.random.randint(0, 2, size=(20, 4))\n",
        "y_test = np.random.randint(0, 2, size=20)\n",
        "X_test = np.array(X_test, requires_grad=False)\n",
        "Y_test = np.array(y_test * 2 - np.ones(len(y_test)), requires_grad=False)\n",
        "\n",
        "# Comparar ambos métodos\n",
        "print(\"\\n--- MÉTODO HÍBRIDO (QNG + GD) ---\")\n",
        "predictions_hybrid = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
        "acc_hybrid = accuracy_score(Y_test, predictions_hybrid)\n",
        "prec_hybrid = precision_score(Y_test, predictions_hybrid, average='macro', zero_division=0)\n",
        "rec_hybrid = recall_score(Y_test, predictions_hybrid, average='macro', zero_division=0)\n",
        "f1_hybrid = f1_score(Y_test, predictions_hybrid, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {acc_hybrid:.4f}\")\n",
        "print(f\"Precision: {prec_hybrid:.4f}\")\n",
        "print(f\"Recall: {rec_hybrid:.4f}\")\n",
        "print(f\"F1-Score: {f1_hybrid:.4f}\")\n",
        "print(f\"Bias final: {bias:.4f}\")\n",
        "\n",
        "print(\"\\n--- MÉTODO QNG PURO (SIN BIAS) ---\")\n",
        "predictions_qng = [np.sign(circuit(weights_qng, x)) for x in X_test]\n",
        "acc_qng = accuracy_score(Y_test, predictions_qng)\n",
        "prec_qng = precision_score(Y_test, predictions_qng, average='macro', zero_division=0)\n",
        "rec_qng = recall_score(Y_test, predictions_qng, average='macro', zero_division=0)\n",
        "f1_qng = f1_score(Y_test, predictions_qng, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy: {acc_qng:.4f}\")\n",
        "print(f\"Precision: {prec_qng:.4f}\")\n",
        "print(f\"Recall: {rec_qng:.4f}\")\n",
        "print(f\"F1-Score: {f1_qng:.4f}\")\n",
        "\n",
        "# Mostrar historial de entrenamiento\n",
        "print(f\"\\nHistorial híbrido - últimas 3 accuracy: {accuracy_history[-3:] if len(accuracy_history) >= 3 else accuracy_history}\")\n",
        "print(f\"Historial QNG puro - últimas 3 accuracy: {accuracy_history_qng[-3:] if len(accuracy_history_qng) >= 3 else accuracy_history_qng}\")\n",
        "\n",
        "# Recomendaciones para el dataset real\n",
        "print(\"\\n=== RECOMENDACIONES PARA DATASET TITANIC ===\")\n",
        "print(\"1. Usar el método híbrido (QNG + GD) para mayor flexibilidad\")\n",
        "print(\"2. Aumentar num_it a 100-200 para mejor convergencia\")\n",
        "print(\"3. Experimentar con stepsize entre 0.005 y 0.05\")\n",
        "print(\"4. Considerar usar más qubits (6-8) para el dataset real\")\n",
        "print(\"5. Normalizar las características antes del entrenamiento\")\n",
        "print(\"6. Usar cross-validation para obtener métricas más robustas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6VTxsCnoO3A",
        "outputId": "ca51d39f-4333-4091-f67e-a7ff42e98e2b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape de los pesos: (2, 4, 3)\n",
            "Pesos iniciales: [[[0.37454012 0.95071431 0.73199394]\n",
            "  [0.59865848 0.15601864 0.15599452]\n",
            "  [0.05808361 0.86617615 0.60111501]\n",
            "  [0.70807258 0.02058449 0.96990985]]\n",
            "\n",
            " [[0.83244264 0.21233911 0.18182497]\n",
            "  [0.18340451 0.30424224 0.52475643]\n",
            "  [0.43194502 0.29122914 0.61185289]\n",
            "  [0.13949386 0.29214465 0.36636184]]]\n",
            "Bias inicial: 0.0\n",
            "Batch size: 10\n",
            "\n",
            "=== INICIANDO ENTRENAMIENTO HÍBRIDO ===\n",
            "QNG para pesos del circuito cuántico, GD para bias\n",
            "Error en iteración 0: unsupported operand type(s) for -: 'float' and 'ExpectationMP'\n",
            "Tipo de error: <class 'TypeError'>\n",
            "\n",
            "=== ENTRENAMIENTO COMPLETADO ===\n",
            "\n",
            "=== ALTERNATIVA: SOLO QNG (SIN BIAS) ===\n",
            "Error en iteración 0: unsupported operand type(s) for -: 'float' and 'ExpectationMP'\n",
            "\n",
            "=== EVALUACIÓN FINAL ===\n",
            "\n",
            "--- MÉTODO HÍBRIDO (QNG + GD) ---\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Recall: 0.5000\n",
            "F1-Score: 0.4949\n",
            "Bias final: 0.0000\n",
            "\n",
            "--- MÉTODO QNG PURO (SIN BIAS) ---\n",
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Recall: 0.5000\n",
            "F1-Score: 0.4949\n",
            "\n",
            "Historial híbrido - últimas 3 accuracy: []\n",
            "Historial QNG puro - últimas 3 accuracy: []\n",
            "\n",
            "=== RECOMENDACIONES PARA DATASET TITANIC ===\n",
            "1. Usar el método híbrido (QNG + GD) para mayor flexibilidad\n",
            "2. Aumentar num_it a 100-200 para mejor convergencia\n",
            "3. Experimentar con stepsize entre 0.005 y 0.05\n",
            "4. Considerar usar más qubits (6-8) para el dataset real\n",
            "5. Normalizar las características antes del entrenamiento\n",
            "6. Usar cross-validation para obtener métricas más robustas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === IMPORTACIONES ===\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import QNGOptimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "# === CONFIGURACIÓN DEL DISPOSITIVO CUÁNTICO ===\n",
        "num_qubits = 4\n",
        "num_layers = 2\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "# === CIRCUITOS CUÁNTICOS ===\n",
        "\n",
        "def stateprep(x):\n",
        "    qml.BasisEmbedding(x, wires=range(num_qubits))\n",
        "\n",
        "# QNode principal que recibe weights y x empacados (para clasificar)\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def qnode_cost(param_pack):\n",
        "    weights, x = param_pack\n",
        "    stateprep(x)\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# QNode auxiliar que solo depende de weights (para adjoint_metric_tensor)\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def qnode_only_weights(weights):\n",
        "    stateprep(global_x)  # usamos la variable global_x externa\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "def classifier(weights, bias, x):\n",
        "    return qnode_cost((weights, x)) + bias\n",
        "\n",
        "# === PREPROCESAMIENTO DEL DATASET TITANIC ===\n",
        "with zipfile.ZipFile(\"titanic.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"titanic_data\")\n",
        "\n",
        "df = pd.read_csv(\"titanic_data/train.csv\")\n",
        "df['Pclass'] = df['Pclass'].astype(str)\n",
        "df = pd.concat([df, pd.get_dummies(df[['Pclass', 'Sex', 'Embarked']])], axis=1)\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "df['is_child'] = df['Age'].map(lambda x: 1 if x < 12 else 0)\n",
        "\n",
        "cols = ['is_child', 'Pclass_1', 'Pclass_2', 'Sex_female']\n",
        "X = df[cols].astype(int).values\n",
        "Y = (df['Survived'] * 2 - 1).values  # {0,1} → {-1,1}\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_train = np.array(X_train, requires_grad=False, dtype=int)\n",
        "X_test = np.array(X_test, requires_grad=False, dtype=int)\n",
        "Y_train = np.array(Y_train, requires_grad=False)\n",
        "Y_test = np.array(Y_test, requires_grad=False)\n",
        "\n",
        "# === INICIALIZACIÓN DE PARÁMETROS ===\n",
        "shape = qml.StronglyEntanglingLayers.shape(num_layers, num_qubits)\n",
        "weights = 0.1 * np.random.randn(*shape)\n",
        "weights.requires_grad = True\n",
        "\n",
        "bias = np.tensor(0.0, requires_grad=True)\n",
        "\n",
        "# === OPTIMIZADORES ===\n",
        "qng_opt = QNGOptimizer(stepsize=0.1)\n",
        "bias_lr = 0.01\n",
        "\n",
        "# === ENTRENAMIENTO ESTOCÁSTICO (por muestra) ===\n",
        "print(\"== INICIO DEL ENTRENAMIENTO ==\")\n",
        "for it in range(30):\n",
        "    idx = np.random.randint(0, len(X_train))\n",
        "    global_x = X_train[idx]  # 👈 variable global leída por qnode_only_weights\n",
        "    y = Y_train[idx]\n",
        "\n",
        "    # Paso 1: actualizar pesos con QNG\n",
        "    metric_tensor = qml.adjoint_metric_tensor(qnode_only_weights)\n",
        "    weights = qng_opt.step(qnode_only_weights, weights, metric_tensor_fn=metric_tensor)\n",
        "    weights.requires_grad = True  # mantener gradiente activo\n",
        "\n",
        "    # Paso 2: actualizar bias con regla de gradiente clásico\n",
        "    pred = qnode_cost((weights, global_x))\n",
        "    grad = -2 * (y - (pred + bias))\n",
        "    bias = bias - bias_lr * grad\n",
        "\n",
        "    # Logging\n",
        "    if it % 5 == 0:\n",
        "        preds = [np.sign(classifier(weights, bias, xi)) for xi in X_train]\n",
        "        acc = accuracy_score(Y_train, preds)\n",
        "        print(f\"Iter {it:2d} | Accuracy: {acc:.3f} | Bias: {bias:.3f}\")\n",
        "\n",
        "# === EVALUACIÓN FINAL ===\n",
        "print(\"\\n== EVALUACIÓN FINAL ==\")\n",
        "preds_test = [np.sign(classifier(weights, bias, x)) for x in X_test]\n",
        "acc_test = accuracy_score(Y_test, preds_test)\n",
        "print(f\"Test accuracy: {acc_test:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dlde-tiH05Hv",
        "outputId": "16542b71-c734-467a-84b2-3b21e2f1cb34"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== INICIO DEL ENTRENAMIENTO ==\n",
            "Iter  0 | Accuracy: 0.369 | Bias: -0.040\n",
            "Iter  5 | Accuracy: 0.369 | Bias: -0.075\n",
            "Iter 10 | Accuracy: 0.369 | Bias: 0.011\n",
            "Iter 15 | Accuracy: 0.369 | Bias: 0.009\n",
            "Iter 20 | Accuracy: 0.369 | Bias: 0.085\n",
            "Iter 25 | Accuracy: 0.369 | Bias: 0.117\n",
            "\n",
            "== EVALUACIÓN FINAL ==\n",
            "Test accuracy: 0.341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === IMPORTACIONES ===\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from pennylane.optimize import QNGOptimizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === CONFIGURACIÓN DEL DISPOSITIVO ===\n",
        "num_qubits = 4\n",
        "num_layers = 4\n",
        "dev = qml.device(\"default.qubit\", wires=num_qubits)\n",
        "\n",
        "# === CIRCUITOS ===\n",
        "def stateprep(x):\n",
        "    qml.BasisEmbedding(x, wires=range(num_qubits))\n",
        "\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def qnode_cost(param_pack):\n",
        "    weights, x = param_pack\n",
        "    stateprep(x)\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "@qml.qnode(dev, interface=\"autograd\")\n",
        "def qnode_only_weights(weights):\n",
        "    # Usa global_x_batch[0] solo como dummy para el cálculo del tensor métrico\n",
        "    stateprep(global_x_batch[0])\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(num_qubits))\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "def classifier(weights, bias, x):\n",
        "    return qnode_cost((weights, x)) + bias\n",
        "\n",
        "# === DATASET TITANIC ===\n",
        "with zipfile.ZipFile(\"titanic.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"titanic_data\")\n",
        "\n",
        "df = pd.read_csv(\"titanic_data/train.csv\")\n",
        "df['Pclass'] = df['Pclass'].astype(str)\n",
        "df = pd.concat([df, pd.get_dummies(df[['Pclass', 'Sex', 'Embarked']])], axis=1)\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "df['is_child'] = df['Age'].map(lambda x: 1 if x < 12 else 0)\n",
        "\n",
        "cols = ['is_child', 'Pclass_1', 'Pclass_2', 'Sex_female']\n",
        "X = df[cols].astype(int).values\n",
        "Y = (df['Survived'] * 2 - 1).values\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "X_train = np.array(X_train, requires_grad=False, dtype=int)\n",
        "X_test = np.array(X_test, requires_grad=False, dtype=int)\n",
        "Y_train = np.array(Y_train, requires_grad=False)\n",
        "Y_test = np.array(Y_test, requires_grad=False)\n",
        "\n",
        "# === PARÁMETROS DEL MODELO ===\n",
        "shape = qml.StronglyEntanglingLayers.shape(num_layers, num_qubits)\n",
        "weights = 0.1 * np.random.randn(*shape)\n",
        "weights.requires_grad = True\n",
        "bias = np.tensor(0.0, requires_grad=True)\n",
        "\n",
        "qng_opt = QNGOptimizer(stepsize=0.1)\n",
        "bias_lr = 0.01\n",
        "\n",
        "# === ENTRENAMIENTO CON MINI-BATCH ===\n",
        "batch_size = 16\n",
        "num_epochs = 100\n",
        "log_interval = 5\n",
        "\n",
        "acc_hist = []\n",
        "bias_hist = []\n",
        "\n",
        "print(\"== INICIO DEL ENTRENAMIENTO ==\")\n",
        "\n",
        "for it in range(num_epochs):\n",
        "    idx = np.random.choice(len(X_train), batch_size, replace=False)\n",
        "    global_x_batch = X_train[idx]\n",
        "    y_batch = Y_train[idx]\n",
        "\n",
        "    # Paso 1: actualizar pesos (usamos solo la primera muestra para adjoint)\n",
        "    metric_tensor = qml.adjoint_metric_tensor(qnode_only_weights)\n",
        "    weights = qng_opt.step(qnode_only_weights, weights, metric_tensor_fn=metric_tensor)\n",
        "    weights.requires_grad = True\n",
        "\n",
        "    # Paso 2: actualizar bias usando promedio del gradiente en el batch\n",
        "    preds = np.array([classifier(weights, bias, xi) for xi in global_x_batch])\n",
        "    grads = -2 * (y_batch - preds)\n",
        "    avg_grad = np.mean(grads)\n",
        "    bias = bias - bias_lr * avg_grad\n",
        "\n",
        "    # Registro\n",
        "    if it % log_interval == 0 or it == num_epochs - 1:\n",
        "        preds_train = [np.sign(classifier(weights, bias, xi)) for xi in X_train]\n",
        "        acc = accuracy_score(Y_train, preds_train)\n",
        "        acc_hist.append(acc)\n",
        "        bias_hist.append(bias.item())\n",
        "        print(f\"Iter {it:3d} | Accuracy: {acc:.3f} | Bias: {bias:.3f}\")\n",
        "\n",
        "# === EVALUACIÓN FINAL ===\n",
        "print(\"\\n== EVALUACIÓN FINAL ==\")\n",
        "preds_test = [np.sign(classifier(weights, bias, x)) for x in X_test]\n",
        "acc_test = accuracy_score(Y_test, preds_test)\n",
        "print(f\"Test accuracy: {acc_test:.3f}\")\n",
        "\n",
        "# === VISUALIZACIÓN ===\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(np.arange(0, num_epochs, log_interval), acc_hist, label=\"Train Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(np.arange(0, num_epochs, log_interval), bias_hist, label=\"Bias\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Bias\")\n",
        "plt.title(\"Bias Evolution\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ06xjQD8Yr-",
        "outputId": "5ece36ee-9026-4ee8-8abe-493c62bb4db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== INICIO DEL ENTRENAMIENTO ==\n",
            "Iter   0 | Accuracy: 0.782 | Bias: -0.002\n",
            "Iter   5 | Accuracy: 0.615 | Bias: 0.003\n",
            "Iter  10 | Accuracy: 0.331 | Bias: 0.041\n",
            "Iter  15 | Accuracy: 0.713 | Bias: 0.030\n",
            "Iter  20 | Accuracy: 0.753 | Bias: 0.055\n",
            "Iter  25 | Accuracy: 0.715 | Bias: 0.058\n",
            "Iter  30 | Accuracy: 0.617 | Bias: 0.073\n",
            "Iter  35 | Accuracy: 0.617 | Bias: 0.098\n",
            "Iter  40 | Accuracy: 0.617 | Bias: 0.101\n",
            "Iter  45 | Accuracy: 0.617 | Bias: 0.133\n",
            "Iter  50 | Accuracy: 0.617 | Bias: 0.129\n"
          ]
        }
      ]
    }
  ]
}